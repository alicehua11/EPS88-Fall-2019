{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Last Glacial Maximum, ice sheet flow, directional data, and bootstrapping\n",
    "\n",
    "## The Last Glacial Maximum\n",
    "\n",
    "Around 20,000 years ago was the last glacial maximum, the most recent of glacial intervals associated with climate going between a glacial and interglacial climate states over the past 2.5 million years. We will look at data associated with more of these cycles when we talk about time-series analysis. For the moment, let's focus on the warming from the last glacial maximum which is visualized (based on estimates published in a couple different scientific papers) in the following xkcd comic:\n",
    "\n",
    "<img src=\"./images/earth_temperature_timeline_2x.png\" width = 600>\n",
    "\n",
    "At the last glacial maximum, the extent of ice sheets on North America were the following such that nearly all of Canada was covered in an ice sheet (like Greenland is today) with this ice sheet extending down into the lower 48 states of the present-day United States:\n",
    "\n",
    "<img src=\"./images/Cordilleran-and-Laurentide-Ice-Sheets.png\" width = 600>\n",
    "\n",
    "> Source https://opentextbc.ca/geology/chapter/16-1-glacial-periods-in-earths-history/\n",
    "\n",
    "This xkcd comic is a helpful visualization of the thickness of the Laurentide ice sheet at the location of a few modern day cities:\n",
    "\n",
    "<img src=\"./images/ice_sheets_2x.png\" width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cordilleran ice sheet\n",
    "\n",
    "Let's focus on the Cordilleran ice sheet which is visualized here:\n",
    "\n",
    "<img src=\"./images/Cordilleran_ice_sheet.png\" width = 500>\n",
    "\n",
    "> Source Booth et al. 2003 where it is modified from Clague (1981)\n",
    "\n",
    "Booth et al. (2003) in their review paper on the Cordilleran ice sheet provide this summary of the history of the most recent growth of the ice sheet.\n",
    "\n",
    "> The Cordilleran ice sheet most recently advanced out of the mountains of British Columbia about 25,000 14C yr B.P. It flowed west onto the continental shelf, east into the intermontaine valleys of British Columbia where it probably merged with the western edge of the Laurentide ice sheet, and south into the lowlands of Washington State (Fig. 8, Table 1). In southern British Columbia and western Washington the Puget lobe filled the Fraser Lowland and the Puget Lowland between the Olympic Mountains and Cascade Range. The Juan de Fuca lobe extended east along the Strait of Juan de Fuca to termine some 100km west of Washingtonâ€™s present coast. Several ice lobes east of the Cascade Range expanded south down the Okanogan Valley and down other valleys farther east. The Fraser-age ice-sheet maximum on both sides of the Cascade Range was broadly synchronous (Waitt & Thorson, 1983). It approximately coincided with the maximum advance of some parts of the Laurentide ice sheet in central North America at about 14,000 14C yr B.P. but lagged several thousand years behind the culminating advance of the most of the Laurentide ice sheet (Lowell et al., 1999; Mickelson et al., 1983; Prest, 1969). *The cordilleran ice sheet, Booth et al. 2003\n",
    "\n",
    "There are a lot of different statements made in the above summary paragraph that come from a lot of different data types. For today, let's focus on the statements regarding the flow direction.\n",
    "\n",
    "This photograph of the Aletsch Glacier in Switzerland provides a striking visualization of ice flow in a modern glacier as detritus associated with rock falls onto the glacier have been stretched out in the direction of ice flow:\n",
    "\n",
    "<img src=\"./images/glacier.png\" width = 500>\n",
    "\n",
    "> The Aletsch Glacier, the largest glacier of the Alps, in Switzerland. Source: By Dirk Beyer - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=352940\n",
    "\n",
    "## Ice-flow indicator compilation, British Columbia and Yukon\n",
    "\n",
    "The data set we will focus on today is a large compilation of indicators of past ice-flow that was published by the British Columbia Geological Survey.\n",
    "\n",
    "> Publication Information:\n",
    "*Ice-flow indicator compilation, British Columbia and Yukon\n",
    "British Columbia Ministry of Energy and Mines, British Columbia Geological Survey Open File 2016-04\n",
    "Geological Survey of Canada Open File 8083\n",
    "H. Arnold, T. Ferbey and A.S. Hickin*\n",
    "\n",
    "> A better understanding of the Cordilleran ice sheet flow history is important for designing, implementing, and interpreting geochemical and mineralogical data from drift prospecting surveys. Building on ice-flow indicator compilations for British Columbia by Ferbey et al. (2013) and Yukon Territory (Lipovsky and Bond, 2014), this map and database illustrate major ice-flow directions for the Canadian sector of Cordilleran ice sheet during the Late Pleistocene.\n",
    "\n",
    "> The data were derived from published and unpublished surficial geology, terrain, and glacial feature maps. Because field data are sparse in the area ~ 300 km south of the British Columbia -Yukon border, new data were generated using digital stereo airphotos, digital derived-stereo orthophoto mosaics, and digital derived-stereo Satellite Pour l'Observation de la Terre (SPOT) imagery. The raw data are integrated into a single database; no attempt was made to reconcile cases where data from different sources conflict. \n",
    "\n",
    "> The integrated database may be downloaded from http://www.empr.gov.bc.ca/Mining/Geoscience/PublicationsCatalogue/OpenFiles/2016/Pages/2016-4.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scientific python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_directions = pd.read_csv('./data/cordillera_ice_directions.csv')\n",
    "ice_directions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do Earth scientists determine the extent and direction of ice sheet flow?\n",
    "\n",
    "As covered in the reading, there the presence of ice lead to a number of different types of features. **What types of features are used in this data set? Let's get all the unique values in the 'Feature' column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_directions['Feature'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Striation & Striation or groove\n",
    "\n",
    "As glaciers flow, they can entrain rocks. If these rocks come in contact with the base of the glacier, they can scratch the underlying rock resulting in striations or scouring out larger-scale grooves:\n",
    "\n",
    "<img src=\"./images/striations.png\" width = 500>\n",
    "\n",
    "> Photograph of glacial striations and grooves on Sioux Quartzite bedrock at Jeffers, Minnesota. At least two directions of ice movement are indicated by crossing (x) pattern of striae. Source: [http://academic.emporia.edu/aberjame/ice/lec01/lec1.htm.](http://academic.emporia.edu/aberjame/ice/lec01/lec1.htm)\n",
    "\n",
    "### Crag-and-tail\n",
    "\n",
    "> Definition: a tadpole-shaped landform developed by glacial erosion of rocks on unequal resistance. The crags are cliffs developed in near-cylindrical masses of strong rock. The tail is formed in softer rocks sheltered from erosion in its lee. Source: http://www.landforms.eu/Lothian/crag%20and%20tail.htm\n",
    "\n",
    "This image from Victoria Island in British Columbia shows both striations and miniture crag-and-tail features:\n",
    "\n",
    "<img src=\"./images/crag-and-tail.png\" width = 500>\n",
    "\n",
    "> Source: https://www.geocaching.com/geocache/GC1HW85_victoria-earthcache-series-3-all-scratched-up\n",
    "\n",
    "Crag-and-tail features can also be much larger such as Abbey Craig, a hilltop overlooking Stirling in Scotland on which a monument to Sir William Wallace was built\n",
    "\n",
    "<img src=\"./images/Abbey_craig.png\" width = 600>\n",
    "\n",
    "> Source: http://lenstalk.com/index.php/albumscotland/album01/album22/album24/L1000139_Abbey_Craig_and_the_Ochils_from_Stirling_Castle\n",
    "\n",
    "\n",
    "### Drumlin, Drumlinoid, Fluted bedrock & fluting\n",
    "\n",
    "Drumlin definition: An elongate hill, streamlined in the direction of ice flow and composed largely of glacial deposits\n",
    "\n",
    "<img src=\"./images/drumlins.png\" width = 300>\n",
    "\n",
    "> Airphoto of Drumlins on Hazelton Peak [British Columbia]. Flow is toward the bottom right of the photo. Some of the stoss (upflow) ends of the drumlins are truncated by cliff faces (A). Stoss-end crescentic furrows are visible that merge with lateral furrows separating the drumlins, thus producing U-shaped furrows (B). Source: *Streamlined erosional residuals and drumlins in central British Columbia* McClenagan (2013) https://doi.org/10.1016/j.geomorph.2013.01.015\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the direction of one measurement\n",
    "\n",
    "### Azimuth\n",
    "\n",
    "Earth science is filled with directional data. The most typical way that directional data are reported is as azimuth:\n",
    "\n",
    "<img src=\"./images/azimuth.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the azimuth of the first data point in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_directions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_azimuth = ice_directions['Azimuth'][0]\n",
    "print(first_azimuth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the x length and y length of the unit vector associated with the azimuth\n",
    "\n",
    "<img src=\"./images/Circle_cos_sin.gif\" width = 600>\n",
    "\n",
    "If $\\theta=0Âº$ $sin(\\theta)=1$ and $cos(\\theta)=0$\n",
    "\n",
    "If $\\theta=90Âº$ $sin(\\theta)=0$ and $cos(\\theta)=1$\n",
    "\n",
    "If $\\theta=225Âº$ $sin(\\theta)= -0.7071$ and $cos(\\theta)= -0.7071$\n",
    "\n",
    "Unfortunately, the trignometric convention is rotated 90Âº from the geographic convention, but the result is that:\n",
    "\n",
    "x_length = sin(azimuth)\n",
    "\n",
    "y_length = cos(azimuth)\n",
    "\n",
    "<img src=\"./images/2D_Direction_Vectors.svg\" width = 600>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrow_lengths(azimuth):\n",
    "    azimuth_radians = np.radians(azimuth)\n",
    "    x_length = np.sin(azimuth_radians)\n",
    "    cosb = np.cos(azimuth_radians)\n",
    "    x_length = cosa\n",
    "    y_length = cosb\n",
    "    return x_length,y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_arrow_lengths(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_length,y_length = get_arrow_lengths(first_azimuth)\n",
    "\n",
    "plt.arrow(0, 0, x_length, y_length,length_includes_head=True,\n",
    "         head_width=0.1, head_length=0.1,color='red')    \n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1,1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=goldenrod>**_Code for you to write_**</font>\n",
    "\n",
    "Use the ```get_arrow_length``` function and add an green arrow pointed north (azimuth of 0) and an orange one pointed southeast (azimuth of 135) onto the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the x length and y length associated with the unit vector of each azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_directions['x_length'] = np.zeros(len(ice_directions))\n",
    "ice_directions['y_length'] = np.zeros(len(ice_directions))\n",
    "\n",
    "ice_directions['x_length'],ice_directions['y_length'] = get_arrow_lengths(ice_directions['Azimuth'])\n",
    "ice_directions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartopy.io.img_tiles import Stamen\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-150, -110, 45, 70])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions['Long']),np.array(ice_directions['Lat']),\n",
    "           np.array(ice_directions['x_length']),np.array(ice_directions['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample the data\n",
    "\n",
    "It is awesome that there are so many datapoints, but it makes it hard to see what the directions are. Let's take a subsample of the data:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\n",
    "\n",
    "We can use the pandas function ```.sample``` to do so specifying how many samples. In this case, we will want ```replace=False``` so that we don't sample the same datapoint twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab 1000 samples and plot them. We could be even more clever and develop a function that sampled with spatial awareness, but for now, let's sample 1000 data points and then plot them on the same map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_directions_subsample = ice_directions.sample(1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-150, -110, 45, 70])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_subsample['Long']),np.array(ice_directions_subsample['Lat']),\n",
    "           np.array(ice_directions_subsample['x_length']),np.array(ice_directions_subsample['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualize all these data on a map would be to change their color based on direction.\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>\n",
    "\n",
    "Make a data frame called ```ice_directions_west``` for flow directions that have an 'Azimuth' greater than 180 and a data frame called ```ice_directions_east``` for flow directions that have an 'Azimuth' less than 180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-150, -110, 45, 70])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_west['Long']),np.array(ice_directions_west['Lat']),\n",
    "           np.array(ice_directions_west['x_length']),np.array(ice_directions_west['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='red',alpha=0.1)\n",
    "plt.quiver(np.array(ice_directions_east['Long']),np.array(ice_directions_east['Lat']),\n",
    "           np.array(ice_directions_east['x_length']),np.array(ice_directions_east['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='blue',alpha=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier to see some of the directions, but it would be nice to summarize there orientation. We have summarized data using histograms before so let's go ahead and do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ice_directions['Azimuth'])\n",
    "plt.xlabel('azimuth flow direction')\n",
    "plt.ylabel('number of flow indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why are histograms not great for visualizing such data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rose diagrams\n",
    "\n",
    "As Earth scientists, we like to make plots that convey the most information with the least amount of effort for the viewer.  2D directional data are much better represented as 'rose diagrams', which are really just histograms plotted around a circle. They are also known as _polar_ projections as they could be used to make a map of the Earth looking down at one of the poles.  \n",
    "\n",
    "We will follow these steps: \n",
    "\n",
    "- For rose diagrams, we will create a  plot instance (called ```fig```) with the ```plt.subplot( )``` function.  We make it a _polar_ plot by setting the ```polar``` keyword to ```True```. \n",
    "- The _polar_ type of subplot has funny coordinates set as default, funny to an Earth scientist at least.  The orientations go around counterclockwise instead of clockwise (like map directions). To make it seem more normal for Earth science data,  we have to switch around the directions to geographic coordinates.  We do this with the **fig.set_theta_direction(-1)** function where the '-1' tells **matplotlib** that we want the numbers to go around clockwise, instead of the default (which for some unknown reason goes counter clockwise).  \n",
    "- We also have to put '0' at the top of the diagram (because it is 'North' in Earth science).  We do that with the ```fig.set_theta_zero_location('N')``` call, which tells ```matplotlib``` to put 0 on top (instead of on the right side which is the default).  \n",
    "-  We have to define some bins, sort of like histograms but around azimuthal circle, and count up how many directions are in each bin.  We will use a bin size of 10$^{\\circ}$.  Fortunately, ```plt.hist( )``` will count up the number of directional data in each bin for us! Usually we just use ```plt.hist()``` to make the plot, but we can also have it return the bins and the number in each bin.\n",
    "- We will use the  plot function **plt.bar( )** which normally makes bar charts, but will make rose diagrams if the plot is _polar_.\n",
    "- Finally, we will plot the data on the figure instance. \n",
    "\n",
    "Let's start with **plt.hist( )** to count up the number in each bin for each set of striations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10 # width of the azimuthal bins\n",
    "binarray = np.arange(0,360+width,width) # make an array to use for bins in plt.hist\n",
    "azimuth_counts, azimuth_bins, patches = plt.hist(ice_directions['Azimuth'],bins=binarray) # get back the counts\n",
    "plt.xlabel('azimuth flow direction')\n",
    "plt.ylabel('number of flow indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few more things.  **plt.bar( )** needs an array of widths that is same same length as our count arrays but with the width (in radians) and also the bin arrays have to be in radians too!  So we need to delete the last bin from binarray and make arrays in radians.\n",
    "\n",
    "So, to finish things off:  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = binarray[0:-1] # delete the last bin\n",
    "thetas = np.radians(bins) # convert the binarray to radians.  \n",
    "widths = np.radians(np.ones(len(thetas))*width) # make the widths array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to make the plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the figure instance\n",
    "fig = plt.subplot(111, polar=True) # Specify polar axes\n",
    "# set the coordinates the way we want them\n",
    "fig.set_theta_direction(-1) # Reverse direction of degrees (CW)\n",
    "fig.set_theta_zero_location(\"N\") # Specify 0-degrees as North\n",
    "# use the polar \"bar\" plot.   \n",
    "fig.bar(thetas, azimuth_counts, width=widths, bottom=0, color='darkblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In and of itself, this result is super cool. The Cordilleran ice sheet was dominantly flowing to the NW towards the Laurentide ice sheet.\n",
    "\n",
    "<img src=\"./images/Cordilleran-and-Laurentide-Ice-Sheets.png\" width = 600>\n",
    "\n",
    "But the Cordilleran ice sheet ice sheet is more complicated than that and has zones with different dynamics. Let's zoom-in on Vancouver Island -- west of Vancouver where the lovely coastal city of Victoria is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-130, -122, 48, 51.5])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions['Long']),np.array(ice_directions['Lat']),\n",
    "           np.array(ice_directions['x_length']),np.array(ice_directions['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='purple')\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[-128.5, 50], width=1.5, height=1,\n",
    "                                    edgecolor='orange',facecolor='none',\n",
    "                                    linewidth=3,\n",
    "                                    transform=ccrs.Geodetic()))\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[-126, 49.1], width=1.4, height=1,\n",
    "                                    edgecolor='red',facecolor='none',\n",
    "                                    linewidth=3,\n",
    "                                    transform=ccrs.Geodetic()))\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[-124.7, 48.1], width=1.5, height=1,\n",
    "                                    edgecolor='brown',facecolor='none',\n",
    "                                    linewidth=3,\n",
    "                                    transform=ccrs.Geodetic()))\n",
    "                      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the map above, I have grouped the data into three zones (north, central and south). Let's filter the dataframe to make separate Vancouver Island north, central and south dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_directions_VI_n = ice_directions[(ice_directions['Long'] < -127.0) & \n",
    "                                     (ice_directions['Long'] > -128.5) &\n",
    "                                     (ice_directions['Lat'] < 51.0) &\n",
    "                                     (ice_directions['Lat'] > 50.0)]\n",
    "\n",
    "ice_directions_VI_c = ice_directions[(ice_directions['Long'] < -124.6) & \n",
    "                                     (ice_directions['Long'] > -126.0) &\n",
    "                                     (ice_directions['Lat'] < 50.1) &\n",
    "                                     (ice_directions['Lat'] > 49.1)]\n",
    "\n",
    "ice_directions_VI_s = ice_directions[(ice_directions['Long'] < -123.2) & \n",
    "                                     (ice_directions['Long'] > -124.7) &\n",
    "                                     (ice_directions['Lat'] < 49.1) &\n",
    "                                     (ice_directions['Lat'] > 48.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot them different colors so that we make sure the filtering worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-130, -122, 48, 51.5])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_VI_n['Long']),np.array(ice_directions_VI_n['Lat']),\n",
    "           np.array(ice_directions_VI_n['x_length']),np.array(ice_directions_VI_n['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='orange')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_VI_c['Long']),np.array(ice_directions_VI_c['Lat']),\n",
    "           np.array(ice_directions_VI_c['x_length']),np.array(ice_directions_VI_c['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='red')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_VI_s['Long']),np.array(ice_directions_VI_s['Lat']),\n",
    "           np.array(ice_directions_VI_s['x_length']),np.array(ice_directions_VI_s['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='brown')\n",
    "                      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rose_diagram(azimuths,color='black',bin_width=10,title='',mean_direction=None):\n",
    "    binarray = np.arange(0,360+bin_width,bin_width) # make an array to use for bins in plt.hist\n",
    "    azimuth_counts, azimuth_bins, patches = plt.hist(azimuths,bins=binarray) # get back the counts\n",
    "    plt.clf()\n",
    "    bins = binarray[0:-1] # delete the last bin\n",
    "    thetas = np.radians(bins) # convert the binarray to radians.  \n",
    "    widths = np.radians(np.ones(len(thetas))*bin_width) # make the widths array\n",
    "\n",
    "    fig = plt.subplot(111, polar=True) # Specify polar axes\n",
    "    fig.set_theta_direction(-1) # Reverse direction of degrees (CW)\n",
    "    fig.set_theta_zero_location(\"N\") # Specify 0-degrees as North\n",
    "    plt.bar(thetas, azimuth_counts, width=widths, bottom=0, color=color)\n",
    "    if mean_direction != None:\n",
    "        plt.bar(np.radians(mean_direction), np.max(azimuth_counts), width=0.01,bottom=0, color='black')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_rose_diagram(ice_directions_VI_n['Azimuth'],color='orange',title='northern Victoria ice flow')\n",
    "make_rose_diagram(ice_directions_VI_c['Azimuth'],color='red',title='central Victoria ice flow')\n",
    "make_rose_diagram(ice_directions_VI_s['Azimuth'],color='brown',title='southern Victoria ice flow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the central directions 180Âº away from the north directions?\n",
    "\n",
    "To calculate a mean direction of directional data, we can't just calculate the arithmetic mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azimuth_1 = 6\n",
    "azimuth_2 = 351\n",
    "\n",
    "np.mean([azimuth_1,azimuth_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a pretty bogus answer as both of these azimuths are pointed north."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_length_1,y_length_1 = get_arrow_lengths(azimuth_1)\n",
    "x_length_2,y_length_2 = get_arrow_lengths(azimuth_2)\n",
    "\n",
    "plt.arrow(0, 0, x_length_1, y_length_1,length_includes_head=True,\n",
    "         head_width=0.1, head_length=0.1,color='darkred')   \n",
    "plt.arrow(x_length_1, y_length_1,x_length_2,y_length_2,length_includes_head=True,\n",
    "         head_width=0.1, head_length=0.1,color='darkblue')   \n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we actually get the mean azimuth direction?\n",
    "\n",
    "<img src=\"./images/resultant_vector.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the x_total and y_total as we have previously calculated the x_length and y_length for every data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total_VI_n = np.sum(ice_directions_VI_n['x_length'])\n",
    "y_total_VI_n = np.sum(ice_directions_VI_n['y_length'])\n",
    "print(x_total_VI_n,y_total_VI_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will draw this on the board and we can see how we can put arctangent to use. And define a function to calculate the mean angular direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_angular_direction(x_total,y_total):\n",
    "    if (x_total > 0) & (y_total > 0):\n",
    "        angle = np.rad2deg(np.arctan(x_total/y_total))\n",
    "    elif (x_total > 0) & (y_total < 0):\n",
    "        angle = 180+np.rad2deg(np.arctan(x_total/y_total))\n",
    "    elif (x_total < 0) & (y_total < 0):\n",
    "        angle = 180+np.rad2deg(np.arctan(x_total/y_total))\n",
    "    elif (x_total < 0) & (y_total > 0):\n",
    "        angle = 360+np.rad2deg(np.arctan(x_total/y_total))\n",
    "    return(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "northern_mean = mean_angular_direction(x_total_VI_n,y_total_VI_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_rose_diagram(ice_directions_VI_n['Azimuth'],color='orange',title='northern Victoria ice flow',mean_direction=northern_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total_VI_c = np.sum(ice_directions_VI_c['x_length'])\n",
    "y_total_VI_c = np.sum(ice_directions_VI_c['y_length'])\n",
    "central_mean = mean_angular_direction(x_total_VI_c,y_total_VI_c)\n",
    "make_rose_diagram(ice_directions_VI_c['Azimuth'],color='red',title='central Victoria ice flow',mean_direction=central_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the central Victoria and northern Victoria ice flow directions antiparallel to one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(northern_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(central_mean+180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_mean+180 == northern_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well do we know the mean directions? \n",
    "\n",
    "But there is scatter in the data. How well do we know the mean directions? \n",
    "\n",
    "If we were assuming a distribution, we could calculate a confidence interval (a standard deviation for example), but we don't know what the distribution can be. We can use the data set itself as an approximation of the population and resampling from it using a statistical technique called **the bootstrap** calculating the mean each time.\n",
    "\n",
    "> The Bootstrap: Resampling from the Sample \n",
    "\n",
    "> What we do have is a large random sample from the population. As we know, a large random sample is likely to resemble the population from which it is drawn. This observation allows data scientists to lift themselves up by their own bootstraps: the sampling procedure can be replicated by sampling from the sample.\n",
    "\n",
    "> Here are the steps of the bootstrap method for generating another random sample that resembles the population:\n",
    "> - Treat the original sample as if it were the population.\n",
    "> - Draw from the sample, at random with replacement, the same number of times as the original sample size.\n",
    "\n",
    "> It is important to resample the same number of times as the original sample size. The reason is that the variability of an estimate depends on the size of the sample. Since our original sample consisted of 500 employees, our sample median was based on 500 values. To see how different the sample could have been, we have to compare it to the median of other samples of size 500.\n",
    "\n",
    "> If we drew 500 times at random without replacement from our sample of size 500, we would just get the same sample back. By drawing with replacement, we create the possibility for the new samples to be different from the original.\n",
    "\n",
    "> Why is this a good idea? By the law of averages, the distribution of the original sample is likely to resemble the population, and the distributions of all the \"resamples\" are likely to resemble the original sample. So the distributions of all the resamples are likely to resemble the population as well.\n",
    "\n",
    "> Source: https://www.inferentialthinking.com/chapters/13/2/Bootstrap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_mean_angles = []\n",
    "\n",
    "for n in range(0,10000):\n",
    "    resampled = ice_directions_VI_c.sample(n=len(ice_directions_VI_c),replace=True)\n",
    "    x_total = np.sum(resampled['x_length'])\n",
    "    y_total = np.sum(resampled['y_length'])\n",
    "    mean_angle = mean_angular_direction(x_total,y_total)\n",
    "    central_mean_angles.append(mean_angle+180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_mean_angles = []\n",
    "\n",
    "for n in range(0,10000):\n",
    "    resampled = ice_directions_VI_n.sample(n=len(ice_directions_VI_n),replace=True)\n",
    "    x_total = np.sum(resampled['x_length'])\n",
    "    y_total = np.sum(resampled['y_length'])\n",
    "    mean_angle = mean_angular_direction(x_total,y_total)\n",
    "    north_mean_angles.append(mean_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(north_mean_angles,alpha=0.5,density=True,color='orange',label='bootstrap resampled northern mean')\n",
    "plt.hist(central_mean_angles,alpha=0.5,density=True,color='red',label='bootstrap resampled antipode of central mean')\n",
    "plt.axvline(x=np.percentile(north_mean_angles,2.5),linestyle='--',color='orange',label='95% confidence interval on northern mean')\n",
    "plt.axvline(x=np.percentile(north_mean_angles,97.5),linestyle='--',color='orange')\n",
    "plt.axvline(x=np.percentile(central_mean_angles,2.5),linestyle='--',color='red',label='95% confidence interval on central mean')\n",
    "plt.axvline(x=np.percentile(central_mean_angles,97.5),linestyle='--',color='red')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(265, 360)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we say that the northern mean and the antipode of the central mean are distinct?\n",
    "\n",
    "**write your answer here and explain why**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
